{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport tensorflow.compat.v2 as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow_datasets as tfds\nfrom tensorflow.python.keras.utils import np_utils\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T03:09:26.051144Z","iopub.execute_input":"2021-06-25T03:09:26.051778Z","iopub.status.idle":"2021-06-25T03:09:26.069586Z","shell.execute_reply.started":"2021-06-25T03:09:26.051724Z","shell.execute_reply":"2021-06-25T03:09:26.066506Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"/kaggle/input/rn2021q1itba-cifar100/submission_example.csv\n/kaggle/input/rn2021q1itba-cifar100/y_train.npy\n/kaggle/input/rn2021q1itba-cifar100/x_test.npy\n/kaggle/input/rn2021q1itba-cifar100/x_train.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train = np.load(\"/kaggle/input/rn2021q1itba-cifar100/x_train.npy\")\nx_test = np.load(\"/kaggle/input/rn2021q1itba-cifar100/x_test.npy\")\ny_train = np.load(\"/kaggle/input/rn2021q1itba-cifar100/y_train.npy\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.072405Z","iopub.execute_input":"2021-06-25T03:09:26.072878Z","iopub.status.idle":"2021-06-25T03:09:26.176486Z","shell.execute_reply.started":"2021-06-25T03:09:26.072813Z","shell.execute_reply":"2021-06-25T03:09:26.175182Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n#Mostramos alguna im√°gen\nidx = 50\nplt.imshow(x_train_val[idx])\nplt.title(f'Clase: {y_train_val[idx]}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.180929Z","iopub.execute_input":"2021-06-25T03:09:26.181264Z","iopub.status.idle":"2021-06-25T03:09:26.357947Z","shell.execute_reply.started":"2021-06-25T03:09:26.181231Z","shell.execute_reply":"2021-06-25T03:09:26.356531Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Dividimos entre train y validaci√≥n\nfrom sklearn.model_selection import train_test_split\n\n\n# x_train, x_val, y_train, y_val = train_test_split(\n#     x_train_val, y_train_val, test_size=0.15, random_state=42, stratify=y_train_val)\n\n# print(np.array(y_train).shape)\n# print(np.array(x_train).shape)\n\n\n# x_train = tf.convert_to_tensor(x_train, dtype=tf.int32)\n# x_val = tf.convert_to_tensor(x_val, dtype=tf.int32)\n# y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n# y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.360495Z","iopub.execute_input":"2021-06-25T03:09:26.360968Z","iopub.status.idle":"2021-06-25T03:09:26.367677Z","shell.execute_reply.started":"2021-06-25T03:09:26.360921Z","shell.execute_reply":"2021-06-25T03:09:26.366181Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\nx_val, y_val = x_train[40000:50000,:], y_train[40000:50000]\nx_train, y_train = x_train[:50000,:], y_train[:50000]\n\nx_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\nx_val = x_val.reshape(x_val.shape[0], 32, 32, 3)\nx_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n\n\ny_train = np_utils.to_categorical(y_train, 100)\ny_val = np_utils.to_categorical(y_val, 100)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.369765Z","iopub.execute_input":"2021-06-25T03:09:26.370388Z","iopub.status.idle":"2021-06-25T03:09:26.712390Z","shell.execute_reply.started":"2021-06-25T03:09:26.370339Z","shell.execute_reply":"2021-06-25T03:09:26.711191Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#Armamos la red de clasificaci√≥n\nfrom tensorflow.keras.layers import Dense, Flatten, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback, TensorBoard\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator  ","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.714086Z","iopub.execute_input":"2021-06-25T03:09:26.714783Z","iopub.status.idle":"2021-06-25T03:09:26.722517Z","shell.execute_reply.started":"2021-06-25T03:09:26.714732Z","shell.execute_reply":"2021-06-25T03:09:26.720802Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data_augmentation = Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.724331Z","iopub.execute_input":"2021-06-25T03:09:26.724898Z","iopub.status.idle":"2021-06-25T03:09:26.748584Z","shell.execute_reply.started":"2021-06-25T03:09:26.724849Z","shell.execute_reply":"2021-06-25T03:09:26.747526Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(128,3, input_shape=(32,32,3)))\nmodel.add(Conv2D(128,3))\nmodel.add(Conv2D(128,1))\n# model.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(128,3))\nmodel.add(Conv2D(128,3))\nmodel.add(Conv2D(128,1))\n# model.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(256,3))\nmodel.add(Conv2D(256,1))\n# model.add(BatchNormalization())\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(100, activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer= Adam(learning_rate=0.001), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.753021Z","iopub.execute_input":"2021-06-25T03:09:26.753402Z","iopub.status.idle":"2021-06-25T03:09:26.895087Z","shell.execute_reply.started":"2021-06-25T03:09:26.753370Z","shell.execute_reply":"2021-06-25T03:09:26.894012Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\nreduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)  \ndatagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=0,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=False)\n\ndatagen.fit(x_train)\n\nit_train = datagen.flow(x_train, y_train, batch_size = 64)\n\nsteps = int(x_train.shape[0] / 64)\nmodel.fit(it_train,\n         validation_data=(x_val, y_val),\n         steps_per_epoch=steps, epochs=50)\n\n#model.fit(x_train_norm, y_train, validation_data = (x_val, y_val), epochs=50, callbacks=[early_stop])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T03:09:26.896775Z","iopub.execute_input":"2021-06-25T03:09:26.897298Z","iopub.status.idle":"2021-06-25T03:38:35.170844Z","shell.execute_reply.started":"2021-06-25T03:09:26.897252Z","shell.execute_reply":"2021-06-25T03:38:35.169569Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/50\n781/781 [==============================] - 37s 46ms/step - loss: 4.2364 - accuracy: 0.0554 - val_loss: 3.4770 - val_accuracy: 0.1648\nEpoch 2/50\n781/781 [==============================] - 36s 46ms/step - loss: 3.4486 - accuracy: 0.1726 - val_loss: 3.0895 - val_accuracy: 0.2383\nEpoch 3/50\n781/781 [==============================] - 36s 45ms/step - loss: 3.1327 - accuracy: 0.2324 - val_loss: 2.8553 - val_accuracy: 0.2862\nEpoch 4/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.9492 - accuracy: 0.2672 - val_loss: 2.8160 - val_accuracy: 0.3021\nEpoch 5/50\n781/781 [==============================] - 36s 46ms/step - loss: 2.8553 - accuracy: 0.2848 - val_loss: 2.6416 - val_accuracy: 0.3366\nEpoch 6/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.7746 - accuracy: 0.3017 - val_loss: 2.4443 - val_accuracy: 0.3710\nEpoch 7/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.6931 - accuracy: 0.3193 - val_loss: 2.5089 - val_accuracy: 0.3533\nEpoch 8/50\n781/781 [==============================] - 36s 46ms/step - loss: 2.6653 - accuracy: 0.3291 - val_loss: 2.3968 - val_accuracy: 0.3774\nEpoch 9/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.6236 - accuracy: 0.3298 - val_loss: 2.3561 - val_accuracy: 0.3986\nEpoch 10/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.5928 - accuracy: 0.3450 - val_loss: 2.3461 - val_accuracy: 0.3970\nEpoch 11/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.5674 - accuracy: 0.3398 - val_loss: 2.2913 - val_accuracy: 0.4081\nEpoch 12/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.5444 - accuracy: 0.3521 - val_loss: 2.2386 - val_accuracy: 0.4121\nEpoch 13/50\n781/781 [==============================] - 36s 46ms/step - loss: 2.5286 - accuracy: 0.3539 - val_loss: 2.2632 - val_accuracy: 0.4082\nEpoch 14/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.4871 - accuracy: 0.3643 - val_loss: 2.1955 - val_accuracy: 0.4317\nEpoch 15/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.4629 - accuracy: 0.3663 - val_loss: 2.2067 - val_accuracy: 0.4168\nEpoch 16/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.4424 - accuracy: 0.3728 - val_loss: 2.3538 - val_accuracy: 0.4028\nEpoch 17/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.4327 - accuracy: 0.3703 - val_loss: 2.2068 - val_accuracy: 0.4230\nEpoch 18/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.4353 - accuracy: 0.3729 - val_loss: 2.2163 - val_accuracy: 0.4371\nEpoch 19/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.4238 - accuracy: 0.3773 - val_loss: 2.0824 - val_accuracy: 0.4488\nEpoch 20/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3950 - accuracy: 0.3806 - val_loss: 2.1514 - val_accuracy: 0.4416\nEpoch 21/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3586 - accuracy: 0.3850 - val_loss: 2.2242 - val_accuracy: 0.4276\nEpoch 22/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.3944 - accuracy: 0.3807 - val_loss: 2.0657 - val_accuracy: 0.4542\nEpoch 23/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3725 - accuracy: 0.3854 - val_loss: 2.1111 - val_accuracy: 0.4541\nEpoch 24/50\n781/781 [==============================] - 36s 46ms/step - loss: 2.3324 - accuracy: 0.3954 - val_loss: 2.1693 - val_accuracy: 0.4383\nEpoch 25/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3558 - accuracy: 0.3939 - val_loss: 2.0306 - val_accuracy: 0.4612\nEpoch 26/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3329 - accuracy: 0.3947 - val_loss: 1.9900 - val_accuracy: 0.4723\nEpoch 27/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.3458 - accuracy: 0.3931 - val_loss: 2.2011 - val_accuracy: 0.4335\nEpoch 28/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.3201 - accuracy: 0.3969 - val_loss: 2.0490 - val_accuracy: 0.4584\nEpoch 29/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.3314 - accuracy: 0.3941 - val_loss: 1.9773 - val_accuracy: 0.4765\nEpoch 30/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3200 - accuracy: 0.4015 - val_loss: 1.9677 - val_accuracy: 0.4797\nEpoch 31/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2935 - accuracy: 0.4018 - val_loss: 2.0659 - val_accuracy: 0.4567\nEpoch 32/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.3230 - accuracy: 0.3949 - val_loss: 1.9827 - val_accuracy: 0.4722\nEpoch 33/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.2768 - accuracy: 0.4058 - val_loss: 2.0204 - val_accuracy: 0.4639\nEpoch 34/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2979 - accuracy: 0.4016 - val_loss: 1.9875 - val_accuracy: 0.4713\nEpoch 35/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2815 - accuracy: 0.4049 - val_loss: 2.0376 - val_accuracy: 0.4594\nEpoch 36/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.2880 - accuracy: 0.4055 - val_loss: 1.9785 - val_accuracy: 0.4752\nEpoch 37/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.2678 - accuracy: 0.4120 - val_loss: 2.0870 - val_accuracy: 0.4581\nEpoch 38/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.2753 - accuracy: 0.4091 - val_loss: 2.0660 - val_accuracy: 0.4535\nEpoch 39/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.2828 - accuracy: 0.4060 - val_loss: 1.9663 - val_accuracy: 0.4812\nEpoch 40/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2646 - accuracy: 0.4103 - val_loss: 1.9522 - val_accuracy: 0.4769\nEpoch 41/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2597 - accuracy: 0.4110 - val_loss: 1.9608 - val_accuracy: 0.4751\nEpoch 42/50\n781/781 [==============================] - 35s 45ms/step - loss: 2.2658 - accuracy: 0.4105 - val_loss: 1.8835 - val_accuracy: 0.4930\nEpoch 43/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.2658 - accuracy: 0.4137 - val_loss: 2.0516 - val_accuracy: 0.4718\nEpoch 44/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2522 - accuracy: 0.4134 - val_loss: 1.9412 - val_accuracy: 0.4819\nEpoch 45/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2563 - accuracy: 0.4148 - val_loss: 1.8794 - val_accuracy: 0.4949\nEpoch 46/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.2466 - accuracy: 0.4156 - val_loss: 1.8230 - val_accuracy: 0.5068\nEpoch 47/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2426 - accuracy: 0.4127 - val_loss: 1.9060 - val_accuracy: 0.4852\nEpoch 48/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2212 - accuracy: 0.4206 - val_loss: 1.9261 - val_accuracy: 0.4891\nEpoch 49/50\n781/781 [==============================] - 35s 44ms/step - loss: 2.2303 - accuracy: 0.4173 - val_loss: 2.0445 - val_accuracy: 0.4645\nEpoch 50/50\n781/781 [==============================] - 34s 44ms/step - loss: 2.2389 - accuracy: 0.4164 - val_loss: 1.8552 - val_accuracy: 0.5004\nModel: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_16 (Conv2D)           (None, 30, 30, 128)       3584      \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 28, 28, 128)       147584    \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 28, 28, 128)       16512     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 14, 14, 128)       0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 12, 12, 128)       147584    \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 10, 10, 128)       147584    \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 10, 10, 128)       16512     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 5, 5, 128)         0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 5, 5, 128)         0         \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 3, 3, 256)         295168    \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 3, 3, 256)         65792     \n_________________________________________________________________\nglobal_average_pooling2d_2 ( (None, 256)               0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_5 (Dense)              (None, 100)               25700     \n=================================================================\nTotal params: 931,812\nTrainable params: 931,812\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]}]}